hydra:
  searchpath:
    - pkg://verl.trainer.config

defaults:
  - ppo_trainer
  - _self_

ray_kwargs:
  ray_init:
    runtime_env:
      env_vars:
        DREAMSIM_CACHE_DIR: "/root/.cache/torch"

data:
  # After prepare_svg_data(), parquet lives in /workspace/data/<org>/<name>/
  train_files: /workspace/data/simple-shapes/train.parquet
  val_files: /workspace/data/simple-shapes/val.parquet
  prompt_key: prompt
  image_key: images
  reward_fn_key: data_source
  return_raw_chat: true  # Using chat format with messages
  max_prompt_length: 1000
  # svgs for this dataset should be very short
  max_response_length: 1000
  train_batch_size: 16
  rollout_batch_size: 64
  shuffle: true
  seed: 1
  max_pixels: 4194304
  min_pixels: 262144
  filter_overlong_prompts: false  # Disabled to avoid multiprocessing deadlock
  sampler: null

algorithm:
  adv_estimator: grpo
  disable_kl: true
  use_kl_loss: false
  use_kl_in_reward: false

actor_rollout_ref:
  model:
    path: Qwen/Qwen2.5-VL-7B-Instruct
    enable_gradient_checkpointing: true
    use_remove_padding: true

  actor:
    strategy: fsdp
    optim:
      lr: 1.0e-5
    ppo_mini_batch_size: 16
    ppo_micro_batch_size_per_gpu: 4
    use_kl_loss: false
    fsdp_config:
      param_offload: true
      optimizer_offload: true

  rollout:
    name: vllm
    mode: sync
    n: 64
    temperature: 1.1
    top_p: 0.99
    gpu_memory_utilization: 0.6
    enforce_eager: false
    enable_chunked_prefill: false
    tensor_model_parallel_size: 2
    log_prob_micro_batch_size_per_gpu: 20
    free_cache_engine: true

  ref:
    log_prob_micro_batch_size_per_gpu: 20
    fsdp_config:
      param_offload: true

critic:
  enable: false

reward_model:
  enable: false
  # Use batch reward manager to speed up reward computation (svg reward)
  reward_manager: "batch"

custom_reward_function:
  # Use remote Modal GPU service for faster reward computation
  path: ./env/svg/svg_rlrf_reward_remote.py
  name: compute_rewards_dict

trainer:
  total_epochs: 15
  max_steps: 500
  project_name: svg_rlrf
  experiment_name: qwen2_5_vl_7b_svg_grpo_verl
  logger:
    - console
    - wandb
  nnodes: 1
  n_gpus_per_node: 8
  val_freq: 5
  val_before_train: true
  val_only: false
  val_generations_to_log: 3
  save_freq: 5
  save_limit: 3
  save_checkpoint_path: /root/checkpoints/svg_rlrf/qwen2_5_vl_7b_svg_grpo_verl
